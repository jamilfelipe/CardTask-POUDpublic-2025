{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python3 code to parse fmriprep confounds file (v1.5.8), and plot motion summary\n",
    "Jamil Bhanji<br>\n",
    "bhanji@psychology.rutgers.edu<br>\n",
    "Apr 13, 2021<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Edit the variables in the cell below and run the cell.\n",
    "* specify preprocessed data directory path\n",
    "* specify path format to the fmriprep confounds file and output file, subject list, task names, run labels\n",
    "* specify True/False to include 1 column for every outlier (use to regress out spikes)\n",
    "    * specify what metrics to use to determine outliers (must be a column name in fmriprep confounds file \n",
    "        e.g. [\"non-stdDVARS\"] - )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### EDIT BELOW to change study specific paths and params #################3\n",
    "preproctopdir = \"/mnt/delgadolab/jamil/opiod_mita/preproc2/fmriprep\" #study directory (full path)\n",
    "#you can include \"ses-01\" or \"ses-02\" in the paths below and run it for one session at a time\n",
    "#eg: confound_file_format = \"/sub-%s/ses-01/func/sub-%s_task-%s_run-%s_bold_confounds.tsv\"\n",
    "#path should start from the top of the preproc folder (preproctopdir)\n",
    "#there should be 4 \"%s\" placeholders that will be filled in later with subject, subject, task, run\n",
    "confound_file_format = \"/sub-%s/func/sub-%s_task-%s_run-%s_desc-confounds_regressors.tsv\" \n",
    "output_file_format = \"/sub-%s/func/sub-%s_task-%s_run-%s_desc-confounds_64plus.tsv\" #this is the name of the motion confounds file that will be created\n",
    "subjectlist =  ['601','603','604','606','607','608','609','610','611','612','613','614','615','616','617','618','622','624','625','626','627','629','630',\n",
    "                   '801','802','803','804','806','807','809','810','811','812','813','814','815','816','817','818','819','820','821','822','823']\n",
    "\n",
    "# it works for multiple tasks, multiple runs (see further below) -- but doesn't work for multiple sessions\n",
    "func_tasks = [\"cardtask\"]#,\"persist\"]\n",
    "func_task_runs = { \n",
    "    \"cardtask\": (\"01\",)#,\n",
    "    #\"persist\": (\"01\",)#after each taskname (must match BIDS taskname) include run labels as list\n",
    "} #comma inside parenthesis is important if there is only one run e.g.: (\"01\",)\n",
    "\n",
    "####multiple tasks, multiple runs example:\n",
    "# func_tasks = [\"cardtask\",\"persist\"]\n",
    "# func_task_runs = { \n",
    "#      \"cardtask\": (\"01\",\"02\"), #after each taskname (must match BIDS taskname) include run labels as list\n",
    "#      \"persist\": (\"01\",)  #comma after single item is important if there is only one run\n",
    "# }\n",
    "######\n",
    "\n",
    "# set to True to add extra outliers to confound output file (e.g., fsl dvars, or framewise displacement) using boxplot thresh\n",
    "include_outliers = False\n",
    "#specify column names below for columns where you want to use the boxplot thresh method\n",
    "outlier_metric_column_names = [\"dvars\"] #it's no longer possible to use multiple outlier metrics (like commented line below)\n",
    "#outlier_metric_column_names = [\"dvars\",\"framewise_displacement\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Run the cell below to create 24 column motion files and plot motion (framewise displacement)\n",
    "* if you want to output something different then edit the function \"fmriprep_confounds_to_24col_plusoutliers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     13
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# extract and plot\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#plotting style specs and display options\n",
    "sns.set(rc={\"axes.labelsize\": 12})\n",
    "#sns.set_style(\"white\")\n",
    "#sns.set_style(\"ticks\")\n",
    "projpalette = \"muted\" #main palette\n",
    "%matplotlib inline\n",
    "\n",
    "def square_and_diff(df):\n",
    "    col_idxs = [df.columns.get_loc(c) for c in df.columns]\n",
    "    for icol in col_idxs:\n",
    "        colsq = df.iloc[:,icol]*df.iloc[:,icol]\n",
    "        coldiff = df.iloc[:,icol].diff()\n",
    "        df = pd.concat([df, colsq], axis=1)\n",
    "        df = pd.concat([df, coldiff], axis=1)\n",
    "        df = pd.concat([df, coldiff*coldiff], axis=1)\n",
    "    return df\n",
    "\n",
    "def make_outlier_columns(crit_data,metric):\n",
    "    upperquartile = crit_data.quantile(.75)\n",
    "    lowerquartile = crit_data.quantile(.25)\n",
    "    outlier_thresh = crit_data.quantile(.75) + 1.5*(upperquartile-lowerquartile)\n",
    "    outliers = crit_data.index[crit_data > outlier_thresh].tolist()\n",
    "    outlier_df = pd.DataFrame(index=crit_data.index)\n",
    "    for counter, outlier_idx in enumerate(outliers):\n",
    "        colname = \"%s%03d\" % (metric,counter)\n",
    "        outlier_df[colname] = 0\n",
    "        outlier_df.iloc[outlier_idx,outlier_df.columns.get_loc(colname)] = 1\n",
    "    return outlier_df\n",
    "\n",
    "def fmriprep_confounds_select(infile, outfile, include_outliers, outlier_metric_column_names):\n",
    "    \"\"\"\n",
    "    Read *_confounds.tsv, select motion, motion^2, deriv, deriv^2\n",
    "    new Apr 2021: select first 5 a_comp_cor WM and first 5 a_comp_cor CSF \n",
    "      (recommendation from Ravi Mill, model 9 in Ciric et al 2017, https://doi.org/10.1016/j.neuroimage.2017.03.020)\n",
    "    Output a tab separated file, BIDS compliant\n",
    "    \"\"\"\n",
    "    #outdf = pd.DataFrame(columns=['onset','duration','trial_type','response_time'])\n",
    "    if not(os.path.isfile(infile)):\n",
    "        #print(\"no file: %s\" % infile)\n",
    "        return pd.DataFrame({'A' : []}), pd.DataFrame({'B' : []})  #return empty dataframe\n",
    "    allconf_df = pd.read_csv(infile, sep='\\t')\n",
    "    outdf = allconf_df[['trans_x','trans_y','trans_z','rot_x','rot_y','rot_z',\n",
    "                        'trans_x_derivative1','trans_y_derivative1','trans_z_derivative1',\n",
    "                        'rot_x_derivative1','rot_y_derivative1','rot_z_derivative1',\n",
    "                        'trans_x_power2','trans_y_power2','trans_z_power2',\n",
    "                        'rot_x_power2','rot_y_power2','rot_z_power2',\n",
    "                        'trans_x_derivative1_power2','trans_y_derivative1_power2','trans_z_derivative1_power2',\n",
    "                        'rot_x_derivative1_power2','rot_y_derivative1_power2','rot_z_derivative1_power2']].copy()\n",
    "    #why these columns? -- see https://doi.org/10.1016/j.neuroimage.2017.03.020 (Ciric et al 2017, NeuroImage)\n",
    "    #consider 'a_comp_cor_XX' columns (e.g., first 5) if not using the aroma-denoised file\n",
    "    #notes from pilot scan -- contrasts look similar with/without aroma, with/without acompcor, but slightly better\n",
    "    #if we don't use aroma and don't use acompcor. this doesn't mean much based on 1 scan.\n",
    "    # add non steady state outliers if any (usually just first volume)\n",
    "    if allconf_df.filter(regex=\"non_steady_state_outliers*\").shape[1] > 0:\n",
    "        outdf = pd.concat([outdf, allconf_df.filter(regex=\"non_steady_state_outliers*\")], axis=1)\n",
    "    # add 5 acompcor WM, 5 acompcor CSF, then add expanded (deriv, square, deriv squared)\n",
    "    # first get the column names from the run specific json file    \n",
    "    colinfo = pd.read_json(infile.replace(\"tsv\",\"json\"))\n",
    "    WMcols = colinfo.loc[:,colinfo.loc['Mask',:]=='WM'].columns[:5]\n",
    "    CSFcols = colinfo.loc[:,colinfo.loc['Mask',:]=='CSF'].columns[:5]\n",
    "    allcols = WMcols.append(CSFcols)\n",
    "    #now get expanded columns and append to out_df\n",
    "    wm_csf_df = square_and_diff(allconf_df[allcols])\n",
    "    outdf = pd.concat([outdf, wm_csf_df], axis=1)\n",
    "    #outdf = square_and_diff(outdf) #square and deriv are in new versions of fmriprep confounds so we don't need this\n",
    "    if include_outliers:\n",
    "        outliers = pd.DataFrame(0,index = allconf_df.index, columns = ['outliers'])\n",
    "        #removed option to have multiple outlier metrics (bc it didn't handle overlapping outliers correctly, and bc\n",
    "        #we don't use it anymore)\n",
    "        metric = outlier_metric_column_names[0]\n",
    "        outlier_cols = make_outlier_columns(allconf_df[metric],metric)\n",
    "        outdf = pd.concat([outdf, outlier_cols], axis=1)\n",
    "        outliers['outliers'] = outliers['outliers'] + outlier_cols.sum(axis=1)\n",
    "        #specify column names below to include outlier columns that are provided by fmriprep\n",
    "        #not implemented yet\n",
    "    else:\n",
    "        outliers = pd.DataFrame(0,index = allconf_df.index, columns = ['outliers'])\n",
    "    outliers.loc[outliers['outliers']>1,'outliers'] = 1\n",
    "    outdf = outdf.round(10)\n",
    "    outdf.fillna(0).to_csv(outfile, sep='\\t', float_format='%.10f', index=False, header=False)\n",
    "    #print(outdf.fillna(0).head())\n",
    "    return allconf_df.framewise_displacement, outliers\n",
    "\n",
    "total_plots = 0\n",
    "for isub, subject in enumerate(subjectlist):\n",
    "    for itask, task in enumerate(func_tasks):\n",
    "        total_plots=total_plots+len(func_task_runs[task])\n",
    "        \n",
    "fig, axarr = plt.subplots(nrows=total_plots, ncols=2, sharey=False, sharex=False, constrained_layout=True) #requires matplotlib>v3.1\n",
    "fig.set_figwidth(16)\n",
    "fig.set_figheight(4*total_plots)\n",
    "#fig.subplots_adjust(hspace=.3)\n",
    "fig.suptitle(\"Framewise Displacement and Outliers (%s >1.5IQR above 75th percentile)\" %(\",\".join(outlier_metric_column_names)), fontsize=22,\n",
    "             fontweight=\"bold\", color=\"black\")#, y= .98, verticalalignment=\"bottom\")\n",
    "\n",
    "fd_data = pd.DataFrame(columns=['subject','task','run','displacement'])\n",
    "outlier_data = pd.DataFrame(columns=['subject','task','run','outliers'])\n",
    "plotnum=0\n",
    "for isub, subject in enumerate(subjectlist):\n",
    "    for itask, task in enumerate(func_tasks):\n",
    "        for irun, run in enumerate(func_task_runs[task]):\n",
    "            if total_plots==1:\n",
    "                ax = axarr[0]\n",
    "                textax=axarr[1]\n",
    "            else:\n",
    "                ax = axarr[plotnum,0]\n",
    "                textax=axarr[plotnum,1]\n",
    "            textax.axis(\"off\")\n",
    "            plotnum=plotnum+1\n",
    "            confoundinfile = (preproctopdir + confound_file_format % (subject,subject,task,run))\n",
    "            outfile24 = (preproctopdir + output_file_format % (subject,subject,task,run))\n",
    "            displacement, outliers = fmriprep_confounds_select(confoundinfile, \n",
    "                                                               outfile24, \n",
    "                                                               include_outliers,\n",
    "                                                               outlier_metric_column_names)\n",
    "            if displacement.empty:\n",
    "                subdf = pd.DataFrame({'subject': subject, 'task': task, 'run': run, 'displacement': 0}, index=range(100))\n",
    "                suboutlierdf = pd.DataFrame({'subject': subject, 'task': task, 'run': run, 'outliers': 0}, index=range(100))\n",
    "                runlabel = \"no run %s data\" % run\n",
    "                ax.text(0,.5, \"no data for  %s\" %(confoundinfile), color=\"red\", fontweight=\"bold\", fontsize=12)\n",
    "            else:\n",
    "                subdf = pd.DataFrame({'subject': subject, 'task': task, 'run': run, 'displacement': displacement.values})\n",
    "                suboutlierdf = pd.DataFrame({'subject': subject, 'task': task, 'run': run, 'outliers': outliers['outliers'].values}, \n",
    "                                            index=range(len(outliers.values)))\n",
    "                runlabel = \"run %s\" % run\n",
    "                #all subjects motion data is saved in one dataframe, fd_data, in case you want to export it\n",
    "                fd_data = fd_data.append(subdf, ignore_index=True)\n",
    "                outlier_data = outlier_data.append(suboutlierdf, ignore_index=True)\n",
    "                ax.plot(fd_data.loc[(fd_data['subject']==subject) & \n",
    "                                    (fd_data['task']==task) & \n",
    "                                    (fd_data['run']==run)]['displacement'].fillna(0).values, label=runlabel)\n",
    "                outlier_plot_vals = np.ma.array(outlier_data.loc[(outlier_data['subject']==subject) &\n",
    "                                                                 (outlier_data['task']==task) & \n",
    "                                                                 (outlier_data['run']==run)]['outliers'].fillna(0).values)\n",
    "                outlier_plot_x = range(len(outlier_plot_vals))\n",
    "                outlier_plot_vals = np.ma.masked_where(outlier_plot_vals < 1 , outlier_plot_vals)\n",
    "                ax.plot(outlier_plot_x, outlier_plot_vals*fd_data.loc[(fd_data['subject']==subject) & \n",
    "                                                                      (fd_data['task']==task) & \n",
    "                                                                      (fd_data['run']==run)]['displacement'].max(),\n",
    "                        \"o\", label=runlabel+\"-outlier\")\n",
    "                ax.set_title(\"subject %s task %s\" % (subject,task),fontweight=\"bold\")\n",
    "                ax.legend(loc='best')\n",
    "                if include_outliers:\n",
    "                    sidetext = \"%d outliers\" %(suboutlierdf['outliers'].sum())\n",
    "                else:\n",
    "                    sidetext = \"no outlier check\"\n",
    "                textax.text(0,.5, sidetext, color=\"red\", fontsize=12)\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errors?\n",
    "* Make sure you have write permission in the fmriprep directory (see fmriprep tips on delgadolab google drive)\n",
    "* Make sure the list of tasks and runs is specified correctly (see comments in 1st code cell) \n",
    "* Double check the file paths in first code cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Add the new confound file to your 1st level glm analysis\n",
    "* e.g., in FSL's Feat, select \"Add additional confound EVs\" and enter the filename for the newly generated motion confound files (e.g., sub-101_task-cardtask_run-01_bold_confounds24plusoutliers.tsv)\n",
    "* in SPM you can specify it as a user-defined covariate (I think that's what it's called)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Export the notebook to html to save the plots and code in a nice portable format\n",
    "* use the notebook's file menu-> Download As -> HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envOpioidMita",
   "language": "python",
   "name": "envopioidmita"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
